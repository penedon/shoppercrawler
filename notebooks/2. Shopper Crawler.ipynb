{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crawler para extração de dados (Shopper)\n",
    "Autor: Gustavo F Penedo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.1 Carregar Requisitos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import undetected_chromedriver.v2 as uc\n",
    "import sys\n",
    "sys.path.append(\"..\") # Upscale notebooks project folder\n",
    "\n",
    "from src.crawler.shopper import ShopperCrawler\n",
    "from src.crawler.config import CrawlerConfig\n",
    "from src.credentials import Credential\n",
    "from src.tools import store_data, latin_to_utf8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Carregar Configurações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Crawler Settings\n",
    "models = CrawlerConfig().models\n",
    "\n",
    "# Load Bot Credentials\n",
    "credential = Credential('shopper')\n",
    "\n",
    "# Start Crawler Object\n",
    "shopper_crawler = ShopperCrawler(\n",
    "    s_key=credential.session_key,\n",
    "    s_password=credential.session_password)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Crawling and Parsing\n",
    "\n",
    "Primeiramente inicia-se o chromedriver para o experimento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome_options = uc.ChromeOptions()\n",
    "chrome_options.add_argument(\"--incognito\")\n",
    "driver = shopper_crawler.initialize_driver(uc.Chrome(options=chrome_options))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.1 Efetuar login e acessar página de extração\n",
    "\n",
    "Efetua-se o login na página e redireciona para a página de extração"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Login\n",
    "shopper_crawler.login()\n",
    "\n",
    "# Página de extração\n",
    "shopper_crawler.access_component_by_xpath('//button')[0].click()\n",
    "shopper_crawler.access_url('https://programada.shopper.com.br/shop/alimentos/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Carregar cada produto da página de extração\n",
    "\n",
    "O método irá acessar categoria por categoria e irá carregar todos os produtos na tela, para que em seguida faça a extração dos modals de cada produto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Products: |||||||||||||||||||||||||||||||||||||||||||||||||| 100.0%\n"
     ]
    }
   ],
   "source": [
    "parsed_products = shopper_crawler.extract_products()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Formatação\n",
    "\n",
    "Nessa seção será feito a formatação dos dados extraídos para se enquadrar na proposta do problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(parsed_products)\n",
    "df.price_to = df.price_to.apply(lambda x: float(x.replace(',', '.')) if x else None)\n",
    "\n",
    "df_assortment = df.copy()\n",
    "df_sellers = df.copy()\n",
    "df_sellers['seller_store'] = df_sellers.store\n",
    "df_sellers['discount_store'] = df_sellers.discount\n",
    "df_sellers['price_store'] = df_sellers.price_to\n",
    "\n",
    "seller_players = pd.DataFrame(list(shopper_crawler.sellers.keys()), columns=['seller_player',])\n",
    "df_sellers = df_sellers.merge(seller_players, how='cross')\n",
    "df_sellers['price_player'] = df_sellers[['sellers', 'seller_player']].apply(\n",
    "    lambda x: x['sellers'][x['seller_player']] if x['seller_player'] in x['sellers'] else None,\n",
    "    axis=1\n",
    ")\n",
    "df_sellers = df_sellers[df_sellers.price_player.notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Armazenamento\n",
    "\n",
    "##### 4.1 Armazena assortment.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/storage/assortment.csv Created\n"
     ]
    }
   ],
   "source": [
    "model = 'assortment'\n",
    "store_data( df_assortment,\n",
    "            shopper_crawler.models[model]['path'], \n",
    "            shopper_crawler.models[model]['columns']\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2 Armazena sellers.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/storage/sellers.csv Created\n"
     ]
    }
   ],
   "source": [
    "model = 'sellers'\n",
    "store_data( df_sellers,\n",
    "            shopper_crawler.models[model]['path'], \n",
    "            shopper_crawler.models[model]['columns']\n",
    "          )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
